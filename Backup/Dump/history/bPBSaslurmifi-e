#!/bin/bash

#------------------------------------------------------------
#-
#-                  Slurm Submission System
#-
#- submit:              sbatch slurm.sh
#- list jobs:           squeue -u $USER
#- cancel jobs:         scancel <jobid> or scancel -u $USER
#- check running job:   scontrol show job -dd <jobid>
#- check completed job: sacct -j <jobid>
#- check CPU & memory:  seff <jobid>  
#- find work directory: find . -name *<jobid>.out
#- check user storage:  diskusage_report
#- check system:        partition-stats
#- data mover:          gra-dtn1.computecanada.ca
#------------------------------------------------------------

#- serial
#-SBATCH --job-name=test
#-SBATCH --account=rrg-fslien     # resource account
#-SBATCH --mail-type=FAIL     # Mail events (NONE, BEGIN, END, FAIL, ALL)
#-SBATCH --mail-user=hmo@uwaterloo.ca     # Where to send mail
#-SBATCH --ntasks=1               # number of tasks
#-SBATCH --mem=1G                 # memory per node --mem=0: full access to a base node
#-SBATCH --time=3-00:00           # time (DD-HH:MM) [3h, 12h, 1d, 3d, 7d, 28d]
#-SBATCH --output=%x-%j.out       # standard output and error log

#- omp
#-SBATCH --job-name=test
#-SBATCH --account=rrg-fslien     # resource account
#-SBATCH --mail-type=FAIL     # Mail events (NONE, BEGIN, END, FAIL, ALL)
#-SBATCH --mail-user=hmo@uwaterloo.ca     # Where to send mail
#-SBATCH --ntasks=1               # number of tasks
#-SBATCH --cpus-per-task=32       # number of processes per task
#-SBATCH --mem=1G                 # memory per node --mem=0: full access to a base node
#-SBATCH --time=3-00:00           # time (DD-HH:MM) [3h, 12h, 1d, 3d, 7d, 28d]
#-SBATCH --output=%x-%j.out       # standard output and error log

#- mpi
#-SBATCH --job-name=test
#-SBATCH --account=rrg-fslien     # resource account
#-SBATCH --mail-type=FAIL     # Mail events (NONE, BEGIN, END, FAIL, ALL)
#-SBATCH --mail-user=hmo@uwaterloo.ca     # Where to send mail
#-SBATCH --nodes=2                # number of nodes
#-SBATCH --ntasks-per-node=32     # number of tasks per node
#-SBATCH --mem=1G                 # memory per node --mem=0: full access to a base node
#-SBATCH --time=3-00:00           # time (DD-HH:MM) [3h, 12h, 1d, 3d, 7d, 28d]
#-SBATCH --output=%x-%j.out       # standard output and error log

#- hybrid
#-SBATCH --job-name=test
#-SBATCH --account=rrg-fslien     # resource account
#-SBATCH --mail-type=FAIL     # Mail events (NONE, BEGIN, END, FAIL, ALL)
#-SBATCH --mail-user=hmo@uwaterloo.ca     # Where to send mail
#-SBATCH --nodes=2                # number of nodes (mpi)
#-SBATCH --ntasks-per-node=8      # number of tasks per node (mpi)
#-SBATCH --cpus-per-task=4        # number of processes per task (omp)
#-SBATCH --mem=1G                 # memory per node --mem=0: full access to a base node
#-SBATCH --time=3-00:00           # time (DD-HH:MM) [3h, 12h, 1d, 3d, 7d, 28d]
#-SBATCH --output=%x-%j.out       # standard output and error log

#- a multi-step job using job arrays
#-SBATCH --array=1-10%1   # Run a 10-job array, one job at a time.

#- In programming terminology, srun is higher level of abstraction than mpirun.
#- Once a particular set of resources is allocated, the nature of an application
#- does not matter (MPI, OpenMP, hybrid, serial, etc.), you just have to srun it.

#- preprocessing
#export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
#module load intel/2016.0.109 openmpi/1.10.2
echo "start at  $(date +'%F %k:%M:%S')"
echo "submit job $(pwd)" >> ~/job_list
echo ""
echo "running on $SLURM_JOB_NUM_NODES nodes with $SLURM_NTASKS tasks with $SLURM_CPUS_PER_TASK processes each."
echo "job array id / job id: $SLURM_ARRAY_JOB_ID / $SLURM_JOB_ID"
echo "this is job $SLURM_ARRAY_TASK_ID out of $SLURM_ARRAY_TASK_COUNT jobs."
echo ""

#- solve
#- case file name
fcas="artracfd.cas"
#- backup file name
fbak="field.case geo_sph.case geo_stl.case"
fpre="$SLURM_ARRAY_TASK_ID"
#- checkpoint file name
fcpt="artracfd.log"
#- checkpoint detection
if [[ -f "$fcpt" ]]; then
    #- program completion checkpoint
    pcpt="$(grep 'completion checkpoint' "$fcpt" | awk '{print $1}')"
    if [[ $pcpt -eq 0 ]]; then
        #- restart uncompleted job from checkpoint data
        dcpt="$(grep 'data checkpoint' "$fcpt" | awk '{print $1}')"
        #- set restart data checkpoint in case file
        sed -i '/restart/c\'"$dcpt   # restart data checkpoint" "$fcas"
        #- backup case files
        for f in $fbak
        do
            if [[ -f "$f" ]]; then
                cp "$f" "$fpre"_"$f"
            fi
        done
    else
        echo "finish at  $(date +'%F %k:%M:%S')"
        exit
    fi
fi

srun artracfd -m omp -n 1*1*32

#- postprocessing part
echo "finish at  $(date +'%F %k:%M:%S')"
echo "complete job $(pwd)" >> ~/job_list

