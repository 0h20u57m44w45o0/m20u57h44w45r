#***************************************************************************#
#                   Data Operation and Manipulation                         #
#                          <By Huangrui Mo>                                 #
# Copyright (C) Huangrui Mo <huangrui.mo@gmail.com>                         #
# under the terms of the GNU General Public License as published by         #
# the Free Software Foundation, either version 3 of the License, or         #
# (at your option) any later version.                                       #
#***************************************************************************#

import numpy as np

def sys_env():
    """ System and running environment.

    Args:
        dirs: files and directories for input and output.

    Returns:
        sysdict: contains environment settings.

    Comments:
        Double quotes for text; Single quotes for anything that behaves
        like an identifier; Tripled double quotes for docstrings.
    """
    sysdict = {
            'delimld': ";,", #* possible non whitespace separators in loading
            'delimsv': ",", #* value separator in saving
            'imdir': "../importer/",
            'procdir': "../processor/",
            'exdir': "../exporter/",
            'optrdir': "../operator/",
            'pldir': "../plotter/",
            'cinfo': "case.info",
            'clist': "case.list",
            'cplot': "artraplot",
            'cols': None, #* columns to load
            'cdim': 2, #* ensure 2D array type
            'fmt': " %12.8g", #* data format in saving
            }
    return sysdict

def delim_detect(cpath, delims):
    """ Detect data value separator.

    Check the first non empty and non comment line to detect delimiter.
    Assume a consistent delimiter for all data lines.

    Args:
        cpath: data file path.
        delims: possible none whitespace delimiters.

    Returns:
        a delimiter.
    """
    with open(cpath, 'r') as cfile:
        line = cfile.readline().strip()
        while not line or line.find('#') != -1:
            line = cfile.readline().strip()
        for c in delims:
            if line.find(c) != -1:
                return c
    #* whitespace delimiter as default
    return None

def process_data(pid, ctag, cdata):
    """ Apply operators to data.

    Args:
        pid: operator identifier.
        ctag: [number of cases, case index, case name].
        cdata: primitive data.

    Returns:
        crlt: processed data.
        headinfo: informative header.
    """
    #* use dict to map a key to a function
    optrdict = {
            'stream': optr_stream,
            'diff': optr_diff,
            'norm': optr_norm,
            'fft': optr_fft,
            'transform': optr_transform,
            'extrema': optr_extrema,
            'convrate': optr_convrate,
            'compute': optr_compute,
            }
    crlt, headinfo = optrdict[pid](ctag, cdata)
    return crlt, headinfo

def optr_stream(ctag, cdata):
    """ Extract and stream data operation.

    Extract via range indexing by slice:
        slice(start,end,step)
        'None' for accessing position extrema.
        '-n' for accessing position in reversed order.
        Slice indexing, scalar indexing, index by start:end:step,
        assignment =, function argument passing all only create
        a pointer to the original array rather than a new array.
        Note: Python always passes mutable objects as references.
    Extract via discrete indexing by list:
        [0, ..., n, ..., N-1]
        List indexing always create a new array rather than a pointer.

    Index a multidimensional array may get a subdimensional array.
    Slice indexing, start:end:step indexing preserve array dimension.
    Otherwise, one can use 'None' to restore collapsed dimensions.
    """
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    crlt = cdata[rls, cls]
    headinfo = "streamed data"
    return crlt, headinfo

def optr_diff(ctag, cdata):
    #* obtain system and running environment
    csys = sys_env()
    #* the base case for comparison
    bname = "base"
    #* detect data delimiter
    bdelim = delim_detect(csys['imdir'] + bname, csys['delimld'])
    #* load case data
    bdata = np.loadtxt(csys['imdir'] + bname, delimiter=bdelim, usecols=csys['cols'], ndmin=csys['cdim'])
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    cdata = cdata[rls, cls]
    bdata = bdata[rls, cls]
    rows, cols = cdata.shape
    absdiff = np.abs(cdata - bdata)
    crlt = np.zeros([5, cols])
    idx = np.argmax(absdiff, axis=0) #* row index for the max element in each column
    crlt[0, :] = idx
    crlt[1, :] = np.amax(absdiff, axis=0, keepdims=False)
    crlt[2, :] = cdata[idx, range(0, cols)]
    crlt[3, :] = bdata[idx, range(0, cols)]
    crlt[4, :] = crlt[1, :] / crlt[3, :] * 100
    headinfo = "[[rid], [maxabsdiff], [raw], [base], [percentage]]"
    return crlt, headinfo

def optr_norm(ctag, cdata):
    """ Compute scaled lp norms.
    """
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    absarr = np.abs(arr)
    rows, cols = arr.shape
    crlt = np.zeros([3, cols])
    crlt[0, :] = np.mean(absarr, axis=0, keepdims=False)
    crlt[1, :] = np.sqrt(np.mean(arr**2, axis=0, keepdims=False))
    crlt[2, :] = np.amax(absarr, axis=0, keepdims=False)
    headinfo = "[[l1 norm], [l2 norm], [max norm]]"
    return crlt, headinfo

def optr_fft(ctag, cdata):
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    rows, cols = arr.shape
    #* parameter
    t = arr[:, 0] #* time variable
    y = arr[:, 1] #* signal variable
    seg = 0 #* samples in Welch's overlap segmented average method, <0|2^n>
    win_type = 'rect' #* window type, <rect|hanning|hamming|...>
    win_para = { #* window parameter (window function, overlap rate)
            'rect': (np.ones, 0),
            'hanning': (np.hanning, 0.5),
            'hamming': (np.hamming, 0.5),
            }
    #* compute
    num = len(y) #* total number of samples in signal
    N = num #* number of samples per segment
    if seg > 1 and seg < num:
        N = seg
    #* scale property of discrete Fourier transform gives t_fov * df = f_fov * dt = 1
    dt = t[1] - t[0] #* sample spacing in time domain
    t_fov = N * dt #* field of view in time domain
    df = 1 / t_fov #* sample spacing in frequency domain
    f_fov = 1 / dt #* field of view in frequency domain
    M = int((N + 1) / 2) #* non-negative sample frequency index upper limit
    f = np.arange(M) * df #* non-negative sample frequency in frequency space
    y = y - np.mean(y) #* remove zero frequency component
    win_weight = win_para[win_type][0](N) #* window weights
    seg_nonlap = int(N * (1 - win_para[win_type][1])) #* non-overlap samples per segment
    num_seg = int((num - N) / seg_nonlap) + 1 #* number of segments
    #* apply fft to each segment data
    y_seg = np.zeros(N) #* store segment signal
    I = np.zeros([M-1, num_seg]) #* store segment energy for positive frequency
    for s in range(num_seg):
        idxl = s * seg_nonlap #* start index for current segment
        idxr = idxl + N #* end index for current segment
        y_seg[:] = y[idxl:idxr] #* segment signal
        y_seg[:] = y_seg - np.mean(y_seg) #* remove zero frequency component
        F = np.fft.fft(y_seg * win_weight, N) #* fft transform
        mag = np.abs(F[1:M]) #* amplitude spectrum for positive frequency
        I[:, s] = mag**2 #* energy intensity
    #* averaged fft over segments, average must be based on energy intensity
    mag_ave = np.sqrt(np.mean(I, axis=1, keepdims=False))
    #* amplitude spectrum in quantity peak, apply transform factor 1/N on fft rather than ifft
    #* since we need the spectrum having amplitude independent on N.
    factor_fft = 1 / N
    #* fft gives a two-sided spectrum of the signal over both the positive and negative frequency,
    #* the coefficients of Fourier transform and Fourier series have the relationship:
    #* c-n = (an + i*bn) / 2, cn = (an - i*bn) / 2, |cn| = |c-n| = sqrt(an^2 + bn^2) / 2 = An / 2
    #* where cn and c-n are the Fourier transform coefficients, an and bn are Fourier series
    #* coefficients. An is the amplitude spectrum. To have the amplitude spectrum of Fourier
    #* transform match each sinusoidal component making up the time-domain signal (based on
    #* function space series), we need to convert the two-sided spectrum to a signal-sided
    #* spectrum via multiplying each frequency amplitude except for zero frequency by two.
    compensate_fft = 2
    #* windowing the original signal would change the amplitude of the signal points accordingly,
    #* which means the loss of the total energy has happened in different degrees. Then in the
    #* spectrum domain, governed by the conservation of energy, the amplitude of spectrum will also
    #* decrease compared with that of without windowing. Therefore, compensation should be applied.
    compensate_win = N / np.sum(win_weight)
    #* total post scale factor
    scale = factor_fft * compensate_fft * compensate_win
    #* compute the scaled amplitude
    A = scale * mag_ave
    #* rms scale factor
    factor_rms = 1 / np.sqrt(2)
    #* amplitude in volts rms
    A_rms = A * factor_rms
    #* compute spl core via A_rms(f)^2 / A_ref^2
    A_ref = 2e-5
    spl_core = A_rms**2 / A_ref**2
    #* SPL
    spl = 10 * np.log10(spl_core)
    #* A weighted SPL
    shift_onek = 1.9974816
    f_sq = f[1:M]**2
    f_weight = 20 * (8.1727197 + 2 * np.log10(f_sq)
            - np.log10(f_sq + 424.36)
            - np.log10(f_sq + 1.488e+08)
            - 0.5 * np.log10(f_sq + 11599.29)
            - 0.5 * np.log10(f_sq + 544496.41))
    spl_A = spl + f_weight + shift_onek
    #* the use of window and energy leakage increase the bandwidth of energy distribution,
    #* then we should introduce the bandwidth factor and effective bandwidth for computing
    #* power spectrum distribution.
    factor_bandwith = N * (np.sum(win_weight**2)) / (np.sum(win_weight))**2;
    #* effective noise bandwidth
    df_eff = factor_bandwith * df
    #* compute power spectrum distribution based on the effective bandwidth
    psd_core = spl_core / df_eff
    #* power spectrum distribution
    psd = 10 * np.log10(psd_core)
    #* assemble data for both zero and positive frequency
    crlt = np.zeros([M, 5])
    crlt[0:M, 0] = f
    crlt[0:1, 1] = np.mean(y) #* recover dc in amplitude spectrum
    crlt[1:M, 1] = A
    crlt[1:M, 2] = spl
    crlt[1:M, 3] = spl_A
    crlt[1:M, 4] = psd
    headinfo = "[frequency, amplitude, spl(dB), spla(dBA), psd(dB)]"
    return crlt, headinfo

def optr_transform(ctag, cdata):
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    rows, cols = arr.shape
    l = 2
    newc = arr[:,0] - l / 2
    crlt = np.c_[newc, arr] #* add a column
    headinfo = "transformed data"
    return crlt, headinfo

def optr_extrema(ctag, cdata):
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    absarr = np.abs(arr)
    rows, cols = arr.shape
    crlt = np.zeros([8, cols])
    crlt[0, :] = np.argmax(absarr, axis=0)
    crlt[1, :] = np.amax(absarr, axis=0, keepdims=False)
    crlt[2, :] = np.argmin(absarr, axis=0)
    crlt[3, :] = np.amin(absarr, axis=0, keepdims=False)
    crlt[4, :] = np.argmax(arr, axis=0)
    crlt[5, :] = np.amax(arr, axis=0, keepdims=False)
    crlt[6, :] = np.argmin(arr, axis=0)
    crlt[7, :] = np.amin(arr, axis=0, keepdims=False)
    headinfo = "[[rid], [absmax], [rid], [absmin], [rid], [max], [rid], [min]]"
    return crlt, headinfo

    """ Least squares fit.

    In mathematics, a basis function is an element of a particular basis for a
    function space. Every continuous function in the function space can be
    represented as a linear combination of basis functions, just as every vector
    in a vector space can be represented as a linear combination of basis vectors.

    Least squares fit p(x) = a0 * fn(x) + ... + an * f0(x) for a function y(x) is
    to decompose a signal y, whose function expression is unknown but its samples
    (xn, yn) can be obtained, into a linear combination of given and known basis
    functions [fn(x)], where [an] are undetermined coefficients, [fn(x)] are basis
    find a vector of coefficients [an] that minimizes the squared error, in other
    words, to minimize the l2 norm of the residual vector r = p(x) - y(x). This is
    equivalent to find the least square solution of the linear system B = AX, where
    B = y, A = [fn(x), ..., f0(x)], X = [a0, ..., an], which is in turn to solve
    the normal equation of the linear system, A'B = A'AX, where A' is A transpose.
    """
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    x = arr[:, 0]
    y = arr[:, 1]
    c = (np.pi - np.arctan2(a[0], -1)) * 180 / np.pi #* slope angle in degree
    crlt = np.zeros([1, 3])
    crlt[0, :] = [a[0], a[1], c]
    headinfo = "[slope, interception, slope angle in degree]"
    return crlt, headinfo

def optr_convrate(ctag, cdata):
    """ Convergence rate.

    Compute the convergence rate for grid refinement studies.
    """
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    rows, cols = arr.shape
    crlt = np.zeros([rows, cols])
    crlt[:, 0] = arr[:, 0] #* copy grid size column
    comptype = 0 #* [0, 1] for [absolute error based, relative error based (require fixed grid ratio)]
    if comptype == 0:
        for m in range(1, rows):
            r = arr[m, 0] / arr[m-1, 0] #* grid refinement ratio
            em = arr[m-1, 1:] #* e(n-1)
            en = arr[m, 1:] #* e(n)
            crlt[m, 1:] = np.log2(em / en) / np.log2(r)
    else:
        for m in range(2, rows):
            r = arr[m, 0] / arr[m-1, 0] #* grid refinement ratio
            em = np.abs(arr[m-2, 1:] - arr[m-1, 1:]) #* e(n-1)
            en = np.abs(arr[m-1, 1:] - arr[m, 1:]) #* e(n)
            crlt[m, 1:] = np.log2(em / en) / np.log2(r)
    headinfo = "[mesh, l1 norm, l2 norm, max norm]"
    return crlt, headinfo

def optr_compute(ctag, cdata):
    #* use dict to map a key to a function
    compdict = {
            'flux': comp_flux,
            'tran': comp_transform,
            }
    crlt, headinfo = compdict['flux'](ctag, cdata)
    return crlt, headinfo

def comp_flux(ctag, cdata):
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    vs = [140, 0, 0]
    x = arr[:, 0]
    y = arr[:, 1]
    z = arr[:, 2]
    nx = arr[:, 3]
    ny = arr[:, 4]
    nz = arr[:, 5]
    rho = arr[:, 6]
    u = arr[:, 7] - vs[0]
    v = arr[:, 8] - vs[1]
    w = arr[:, 9] - vs[2]
    p = arr[:, 10]
    T = arr[:, 11]
    rows, cols = arr.shape
    ary = np.zeros([rows, 3])
    #* turn coordinate pairs into angles distributed in [0, 2pi], counter clockwise
    ary[:, 0] = (np.pi - np.arctan2(y, -x)) * 180 / np.pi
    ary[:, 1] = u * nx + v * ny
    ary[:, 2] = np.abs(ary[:, 1])
    #* sort the resulting array by the anlge column
    idx = np.argsort(ary[:, 0])
    crlt = ary[idx, :] #* use idx[::-1] if reverse order
    headinfo = "[angle, flux, absflux]"
    return crlt, headinfo

def comp_transform(ctag, cdata):
    rls = slice(None, None, None)
    cls = slice(None, None, None)
    arr = cdata[rls, cls]
    rows, cols = arr.shape
    ary = np.zeros([1, 4])
    ary[0, :1] = [int(s) for s in ctag[2].rsplit('_', 1) if s.isdigit()]
    ary[0, 1:] = arr[:, -1]
    crlt = ary
    headinfo = "[mesh, l1 norm, l2 norm, max norm]"
    return crlt, headinfo

